----------------------------------------------------------------------------------------------------------------------------------
Prompt for Deep Research Prompt
----------------------------------------------------------------------------------------------------------------------------------
You are a researcher and a generative AI prompt engineer. Can you create a prompt to research on how [topic & challenge]. I want it to be a detailed [report type] report. The prompt will be used on [LLM]
The focus should be on [iterate what you want the prompt to achieve], And how it will be useful.

Example: You are a researcher and a generative AI prompt engineer. Can you create a prompt to research on how AI companies and TCS competitors is going on about hackathons and vibe coding. I want it to be a detailed comparison, (or deep dive, exploratory, etc) report. The prompt will be used on ChatGPT
The focus should be on what others do and how it can be done in TCS context. And how it will be useful.


----------------------------------------------------------------------------------------------------------------------------------
Deep research prompt
----------------------------------------------------------------------------------------------------------------------------------
Generated by Chat GPT, Reviewed & edited by H-I-T-L

***Prompt should include:*
- System role (you are a ?)
- Instruction details (please produce a?. )
- Sections & topics to cover (structure the report into 5 sections?)
- Details & specifics (the report should include?)
- Specific asks (create a comparative matrix / prioritized list of use-cases / etc?)
- Applying insights to our context (map x to a possible y?)
- Propose Action (Next steps, End result, etc?)
- Formatting standards (Format the report using?)
- Tone & depth (Professional, yet conversational?)
- Sources (for this research, refer to?)
- Citation Note (Do not speculate. Site what you find?)

----------------------------------------------------------------------------------------------------------------------------------
Prompt to Merge Research 
----------------------------------------------------------------------------------------------------------------------------------
I have uplaoaded [Number of] deep research reports from [LLMs used]. For [topic/challenge]. I would like you to read through all of them, combine the information and give me one merged report that has all the information. Keep the content concise and to the point. Make sure that no information or content is missed. At the end of the report create a [specific information or extraction from the report for the next step]

Ex. Use a table to show all the (prioritized) use-cases (with goal, description and potential benefits)


----------------------------------------------------------------------------------------------------------------------------------
Prompt for Use Case Identification 
----------------------------------------------------------------------------------------------------------------------------------
(Optional if goal is to ideate on possible use-cases)

I want you to make a list of possible AI interventions that can bring business value in the space of [topic/challenge]. I want you to then make a list of top use cases / AI features for the same. When making this list, I want you to be very critical in your choice and back the same with research that is not older than 3 months and define why this choice adds most value. I want you to then take the top 3 ideas and detail them out. Details should include a concept name, short description, executive summary, USP & Benefits, user flows for the concept, expected results and quantified business value that the use case brings. I want you to cite sources for the information you collect.

----------------------------------------------------------------------------------------------------------------------------------
Prompt to Fact check Research
----------------------------------------------------------------------------------------------------------------------------------
Based on your research report and internet search, can you fact check this text. Make sure fact check each and every claim from the report. Do not force fit any citations. Do not make direct edits to the report. Instead, only list gaps.

----------------------------------------------------------------------------------------------------------------------------------
Prompt to make Corrections based on fact checks
----------------------------------------------------------------------------------------------------------------------------------
Make the corrections as mentioned above and provide the corrected text with sources. Add the original text for (unchanged) content and give a complete standalone corrected text.

----------------------------------------------------------------------------------------------------------------------------------
Prompt to Generate overview slide 
(Optional if goal is to generate a power-point)
----------------------------------------------------------------------------------------------------------------------------------
Now provide all of these as slide content separated by ---- for different slides. Make sure to expand on the points as it is going to be a self-reading material.
(to be pasted in a tool like Gamma / Genspark / Claude / etc.)

----------------------------------------------------------------------------------------------------------------------------------
Prompt to Detail out use case
----------------------------------------------------------------------------------------------------------------------------------
Using all the information you have, Create a detailed Report on [selected Use-case/feature]. The use-case should include details on: [Hackathon Requirements]


_________________________________________________________________________________
Next Steps:
----------------------------------------------------------------------------------------------------------------------------------


----------------------------------------------------------------------------------------------------------------------------------
Prompt to Create PRD
----------------------------------------------------------------------------------------------------------------------------------
Based on the chat history and all information shared, give me a PRD Document that can be given to an [AI coding assistant] for [use-case or Feature]. The PRD should be in a .md format. Make sure that you use the information from this chat history and do any additional research needed to build the PRD. The PRD should include:
* Purpose
* Core Principles
* Goal
* Why this 
* What will it do
* Success Criteria
* All content needed
* Documentation & References (list all context needed to implement the feature)
* Codebase Tree with files to be added
* Known Gotchas of our codebase & Library Quirks
* Implementation Blueprint
* Data models and structure
* list of tasks to be completed to fullfill the PRP in the order they should be completed
* Per task pseudocode as needed added to each task
* Integration Points
* Validation Loop
* Level 1: Syntax & Style
* Level 2: Unit Tests each new feature/file/function use existing test patterns
* Level 3: Integration Test
* Final validation Checklist
* Anti-Patterns to Avoid
* UI Instructions for the build based on common practices
* Any other relevant information required for the PRD.


----------------------------------------------------------------------------------------------------------------------------------
Rapid Build basis PRD? 
(Lovable, V0, Cursor, Claude Code)
----------------------------------------------------------------------------------------------------------------------------------
Execute the attached PRD.md file. Use information from the PRD only. Do not change many things.













_________________________________________________________________________________
Other Prompts/ Sample References



Deep Research / Context mining prompts:
ÿOption 1
You are a researcher for an AI Rapid build Team within an IT & services company and are going to build demos that show AI capabilities for a Gas & Energy company in Australia. For this, I need you to do deep research on the state of AI adoption in the domain of gas and energy suppliers in Australia. We have had a meeting with the sales team in Australia. I need you to validate the claim that customer service desk and ASP(Accredited Service Provider) onboarding would be the ideal areas to build AI use cases for the energy & gas company. Following this, I need you to specify what, AI enabled use-cases will have most value to them. Please focus on use cases that can be demo-able via video in a meeting. Refer to any and all documents and research you can find for your findings, specifically research papers & news sources around the topic.
The research must include: a summary of the state of AI adoption in Australian mass & energy companies, AI investments made and future plans, where & how we can help in their AI journey, and a list of relevantÿ AI use cases with information on the use case goal, description, AI capabilities used, broad user flow and potential benefits.
ÿ
Option 2:
You are an enterprise CX analyst.ÿ
Objective: Give me a concise, evidence-backed snapshot of Adobe?s current contact-center set-up for Creative & Document Cloud.
Please cover:
1. Primary BPO / vendor partners, locations, seat volumes (voice, chat, email).ÿ
2. Channel mix, languages, and hours-of-operation.
3. Split of workloads: Customer Service vs Tech Support vs Retention vs Inbound/Outbound Sales.ÿ
4. Reported KPIs (AHT, CSAT, NPS, FCR) and any pain-points called out by Adobe execs, agents, or customers.ÿ
5. Technology stack in production (cloud telephony, CRM, knowledge, AI-assist, RPA, etc.) with notable pilots or migrations.
6. Recent news, earnings-call quotes, or job postings that signal upcoming changes (e.g., GenAI rollout, vendor transition).
Sources accepted: financial filings, analyst notes, press releases, vendor case studies, industry news, LinkedIn posts.ÿ
Do **not** speculate?cite what you find.ÿ
Return a bulleted executive brief (ó 400 words) plus a tiny reference list (URLs or article titles).ÿ
ÿ

Idea shortlisting & summary:ÿ
Ok, for Use-case 3 (AI ASP Onboarding), I would like you to give all of the information you have (Goals, Description, flow, impact, etc.) Please identify any external documents I should refer to for this as well like the ASP Scheme rules.

Idea building 
You are a Product Design AI helping me flesh out a rapid-build demo called ?Sales-Call Simulation Agent.?
1. **Scope & Goal**
? Turn a single-line use-case idea into a clickable demo concept that looks like an AI-powered sales-training web app.ÿ
? Output must include: demo features, homepage (dashboard) block descriptions, and a detailed call-simulation flow.
2. **Reference UI Elements**ÿ
Use these UI anchors (already prototyped):ÿ
- Left nav: Dashboard | Simulation | Reportsÿ
- Dashboard cards:ÿ
a. Rep Profile card with radar-chart skill ?spiderweb? (Listening, Empathy, Objection, Value, Closing).ÿ
b. Training Progress donut (show % and level).ÿ
c. Next Challenge card (title + micro-copy).ÿ
d. AI Tutor chat area (LLM Q&A).
e. ?Start New Simulation? dropdown (difficulty selector).ÿ
ÿ
Rapid build prompt for o3:
Give me a script for an [descriptive demo title], for the company [Company Name] ÿto build a front end demo using next js for a Gen AI infused [descriptive (action based) demo title], that allows [Actions, processes, steps, capabilities].
[Add Documents If any] I have attached [#of documentd] documents for your reference: [Document Descriptions].ÿCreate the next js for the front end using the attached document with context & step by step actions
We will focus on [topic/feature being covered] which will involve the following steps (screens): [step by step flow]
We want this to be a working app that uses Tavily search API to do any research tasks. Summary is done using GPT 5 through Open AI API.

Keep the layout & design simple and clean. Use UI elements to make the UI a lot more visual & interactive. [any specific UI instructions if needed]. Use [company]'s ÿbrand colours ([color Hex Value], Grey & white ) template and keep [Device specific size]. Use the script in the attached file for the demo conversation.
ÿ
ÿSample:

 ÿGive me a script for an  (ASP Onboarding Portal), for the company Energy Australia ÿto build a front end demo using next js for a Gen AI infused  (Application & Onboarding portal for ASPs (of a Gas & energy company in Australia), that allows  ASPs to apply, share ASP details (image attatched), upload documents across required categories, read/analyse documents, provide a summary & validation of uploaded documents with an option to upload missing or expired ones. This is followed by a screen for live induction via online call. Once the call ends, the Application is submitted for approval.
I have attached 3 documents for your reference: Image of the ASP details (for step 1), challenge, context & ideal process word Doc, and a pdf of ASP Accredition Scheme rules (for reference of what documents are required).ÿ
Create the next js for the front end using the attached document with context & step by step actions
We will focus on the onboarding which will involve the following steps (screens): 
1. Share ASP Company Details & Qualification (accreditation Document, Level, Grade, etc)
2. Document Upload & (AI) Review for:
* Trainings completed (uploaded Certificates & transcripts)ÿ
* Insurance Requirements (Certification of currency for each)
* Management Systems (Attached list from PDF- pg. 19)
* Registration of employee Letters
3. All the documents uploaded are read & summary report created (checks and gaps + request to upload missing documents)
4. Congratulations message for Document verification.
5. Induction of safety & Operating (Video Call): Conducted online (Possibly with TAVUs) to cover safety and operating procedures. (can be questioned as well with follow-ups)
6. Your Application has been submitted for approval You should get a response within 2-5 days + AI FAQ Chat Window for further querying.
Keep the layout & design simple and clean. Use UI elements to make the UI a lot more visual & interactive. keep a left column for application, Document upload & Induction steps of the process. Use  Energy Australia?sÿbrand colours (Green: #318923, Grey & white ) template and keep  laptop screen size (16:9 ratio). Use the script in the attached file for the demo conversation.


Rapid build prompt generation for o3:

I want to create a Web app that [Idea] does a deep research of TCS competitors and provides actionable insights to TCS executives along with the competitors AI narratives and AI Investments/Platforms.
[API Keys] Use Tavily API for the research tasks. And use gpt-5 via OpenAI API for synthesising and summarising the research data for the TCS Executives.
Create a v0.dev product requirements prompt to build the above feature in a single shot.
Template:
Build a [descriptive demo title], for the company [Company Name] to build a working demo using next js for a Gen AI infused [descriptive (action based) demo title], that allows [Actions, processes, steps, capabilities]. [Add Research Material If any]. Create the app using the PRD with context & step by step actions We will focus on the [Feature] which will involve the following steps (screens): [step by step flow] Keep the layout & design simple and clean. Use UI elements to make the UI a lot more visual & interactive. [any specific UI instructions if needed]. Use [company]'s brand colours ([colour Hex Value], Grey & white ) template and keep [Device specific size].







PRD + v0/cursor, Transfer requires:ÿ
ÿ
1. Save generated result as .md

2. upload to v0

3. Prompt:ÿ
Build a next JS frontend for a Gen AI infused ASP Applocation & Onboarding Portal (of a Gas & energy company in Australia) using the attached fie. Keep the code in the file. do not change many things.

4. Prompt v0 for finetuning (add button, add page, rename, whan i click x, y should happen)





ÿ
API prompts for :
ÿ
Tavus:
When the ?Join Induction Call? Button is clicked, I would like a pre-recorded video to play. When the video is at 9 seconds, pause the video. when end call button is clicked, close the video and go back to the Induction call screen. Make sure that the video takes up the entire live call area. This is API format to call video to play when join call is clicked.
const options = {method: 'GET', headers: {'x-api-key': '<api-key>'}};
ÿ
fetch('https://tavusapi.com/v2/videos/90a6ba025a', options)
ÿ .then(response => response.json())
ÿ .then(response => console.log(response))
ÿ .catch(err => console.error(err));
ÿ
ÿ
Response 200:
{
ÿ "video_id": "",
ÿ "video_name": "<string>",
ÿ "status": "ready",
ÿ "data": {
ÿ ÿ "script": "<string>"
ÿ },
ÿ "download_url": "<string>",
ÿ "stream_url": "<string>",
ÿ "hosted_url": "<string>",
ÿ "status_details": "<string>",
ÿ "created_at": "<string>",
ÿ "updated_at": "<string>",
ÿ "still_image_thumbnail_url": "<string>",
ÿ "gif_thumbnail_url": "<string>"
}
ÿ
API_KEY = 0ccc50d62cf2493e9d5b2df5f6378ad1 ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ ÿ
Video ID =ÿ90a6ba025a
Replica ID = rf4703150052
ÿ
Once demo built & recorded:
Script Generation prompts:
ÿ
You are an expert writer for video production company. We are building a demo video for a Gen AI infused customer support AI Agent for a company that maintains maps app listings. The demo does the following things:ÿ
1. Call a business and check for the owner
2. Have a conversation with the owner, verifying the Listing information.
3. Geotag the location
4. Push updates to Apple Maps
ÿ
I already have the VoiceOver for the cal conversation. I want you to give me an Intro and outro script for this demo that is about 30seconds each, using the attached word document which includes context & step by step actions in the video. Focus on the context and the sections in blue (actions taken) for the narrator script. The script should include a short 3 second intro, context setting, and then explain the user flow and it's benefits.
ÿ
ÿ
H-I-T-L Review & changes>
Script cleaning:
This is the script we have finalised on. I want you to go through it and make recommendations to improve it grammatically. Do not make direct changes to the script. instead make recommendations. also, tell me how log this script will be.




Build a Competitor AI Radar, for the company TCS to build a working demo using Next.js for a Gen-AI infused executive research console, that allows automated deep-dive research on named competitors, maps their AI narratives and product/platform bets, and turns raw sources into crisp executive-ready insights with citations, comparisons, and exportable briefings. Use Tavily API for research and OpenAI (model: gpt-5) for synthesis/summarization. Create the app using the PRD below with context & step-by-step actions. We will focus on the ?Competitor AI Radar ? Research ? Synthesize ? Brief? feature which will involve the following steps (screens): 1) Scope & Inputs, 2) Research Queue & Progress, 3) Evidence Locker, 4) Insights & Executive Brief, 5) Compare & Scorecards, 6) AI Narratives & Investments Catalog, 7) Sources & Citations, 8) Exports & Alerts, 9) Settings & Governance. Keep the layout & design simple and clean. Use cards, tabs, tables, accordions, timelines, progress bars, and comparison matrices to make the UI visual & interactive. Use TCS brand colours (Primary ?TCS Blue? #0079C1, greys, and white) and keep desktop 1440?900 as the default canvas with responsive behavior for 1280+ widths.

# Context & Goals

* Audience: TCS executive leadership and strategy teams who need fast, reliable competitive intelligence on AI narratives, investments, platforms, and go-to-market.
* Outcome: A repeatable workflow that goes from ?list of competitors? ? ?trusted evidence? ? ?actionable insights with clear recommendations? in minutes.
* Guardrails: Always show sources, timestamps, and coverage; highlight uncertainty; avoid hallucination by grounding every claim in at least one cited source.

# Tech Stack

* Framework: Next.js (App Router), TypeScript, React Server Components.
* UI: Tailwind CSS, shadcn/ui components, lucide-react icons.
* Data: Edge-friendly store (Vercel KV/Upstash) for jobs and cache; SQLite/Prisma (or Postgres) for persisted entities (Competitor, Evidence, Insight, Narrative, Investment, Run).
* APIs:

  * **Tavily** for web research. Use advanced depth, domain filters, and return raw content + links.
  * **OpenAI** (model `gpt-5`) for synthesis & structured extraction via the Responses API with JSON mode and tool-style schemas.
* Infra: Route handlers under `/api/*`, server actions for long-running jobs, streaming UI with Server-Sent Events for progress.

# Environment & Secrets

* `TAVILY_API_KEY`
* `OPENAI_API_KEY`
* Optional: `ALLOWED_DOMAINS` (comma-separated), `MAX_SOURCES_PER_COMPETITOR`, `RATE_LIMIT_RPM`.

# Core Data Model (simplified)

* **Competitor**: id, name, ticker?, segments\[], homepage, notes.
* **Evidence**: id, competitorId, url, title, publishedAt, excerpt, fullTextHash, sourceType (news/blog/report/filing/site), credibilityScore, fetchedAt.
* **Narrative**: id, competitorId, thesis (short), pillars\[], targetCustomers\[], proofPoints\[], risks\[], lastUpdated.
* **Investment**: id, competitorId, type (R\&D/Acquisition/Partnership/Fund), name, amount?, date?, strategicRationale, sources\[].
* **Platform**: id, competitorId, productName, category (model, agent, tooling, infra, vertical app), capabilities\[], pricing?, maturity (beta/GA), sources\[].
* **Insight**: id, competitorId?, title, summary, implicationsForTCS, confidence (0?1), heat (Low/Med/High), citations\[evidenceIds].
* **Run**: id, scope {competitors\[], topics\[]}, status, startedAt, completedAt, stats {urlsFetched, deduped, coverage%}.

# High-Level Flow

1. **Scope competitors & topics** ? 2) **Research (Tavily jobs)** ? 3) **Evidence locker (dedupe, cluster, tag)** ? 4) **Synthesis (gpt-5)** ? 5) **Executive brief & recommendations** ? 6) **Compare & score** ? 7) **Export & alert**.

# Screens (Step-by-Step)

## 1) Scope & Inputs

* Form: competitors (chips with suggestions), focus areas (checkboxes: models/agents/tooling/platforms/partnerships/GTMs/verticals/pricing), time window, regions, allowed/excluded domains, depth.
* Actions: ?Run Research?, ?Load Saved Scope?.
* UX: clean card, multi-selects, helper text. Show estimated runtime and coverage gauge.

## 2) Research Queue & Progress

* Real-time list of jobs with status pills (Queued, Fetching, Parsing, Clustering, Summarizing, Done).
* Each job shows progress bars, URLs discovered, deduped count, and a ?View Evidence? CTA.
* Backend: `/api/research/start` enqueues per-competitor tasks; `/api/research/stream` streams progress.

## 3) Evidence Locker

* Table with columns: Relevance, Source, Title, Date, Competitor, Type, Coverage tags.
* Facets on left (source type, date, domain, competitor, topic).
* Row click opens a right-side drawer: full excerpt, highlighted matched spans, and ?Send to Brief? toggle.
* Batch actions: ?Add to Insights Draft?, ?Exclude domain?, ?Mark as Low Credibility?.

## 4) Insights & Executive Brief

* Two-pane editor:

  * Left: ?Draft Insights? (LLM-generated cards with title, what?s new, why it matters, implications for TCS, confidence, citations).
  * Right: ?Executive Brief? (sections: Snapshot, AI Narrative, Investments & Platforms, Moves & Signals, Risks, What TCS Should Do Next).
* Controls: ?Regenerate with Constraints?, ?Tighten to 1-pager?, ?Add Charts?, ?Tone: Board/Tech/Sales?.
* Always show inline citations with hover to preview Evidence and open source link.

## 5) Compare & Scorecards

* Matrix compare: competitors ? dimensions (Narrative Clarity, Investment Intensity, Platform Maturity, Ecosystem, GTM, Differentiation).
* Visuals: heatmap cells with tooltips, sparkline for velocity over time.
* Toggle between ?Auto-scored (LLM)? and ?Manual override?.

## 6) AI Narratives & Investments Catalog

* For each competitor: narrative pillars, investment timeline (horizontal timeline component), known platforms/products with category chips.
* Click any item to see primary citations and extracted quotes.

## 7) Sources & Citations

* List all sources used with domain, date, and how many insights they support.
* Download sources CSV.

## 8) Export & Alerts

* Export: PDF and PPTX (1-pager and deck), plus Markdown.
* Alerts: ?Create weekly digest? and ?Notify me when X changes? (placeholder switch with mocked schedule for demo).

## 9) Settings & Governance

* Enter API keys, configure rate limits, allowed domains, retention period.
* Audit log: who ran what, when, and which sources were used.

# Research Orchestration (Backend)

### Tavily Fetch

* Endpoint: `POST /api/research/fetch`
* Request: `{ competitor, topics[], timeWindow, includeDomains[], excludeDomains[], searchDepth: "basic"|"advanced", maxResults }`
* Behavior:

  * Call Tavily search per topic: queries like `"COMPANY + (AI OR GenAI OR LLM OR agents OR platform OR foundation model OR acquisition OR partnership OR roadmap)"`.
  * Request raw content when available.
  * Respect include/exclude domains; dedupe by URL + content hash; score credibility using a simple heuristic (domain whitelist, recency, cross-source overlap).

### Evidence Normalize

* Parse title, author, publishedAt, excerpt, fullText (if returned), sourceType, and topical tags.
* Store Evidence and link to Competitor.

### Synthesis with OpenAI gpt-5

* Endpoint: `POST /api/summarize/insights`
* Mode: Responses API with JSON schema; enable structured output and citations.
* Prompts (system):

  * ?You are a competitive-strategy analyst for TCS. Only write claims supported by cited evidence. Prefer precise dates. Flag uncertainties. Output JSON that matches the provided schema.?
* Prompts (assistant tools):

  * Provide Evidence objects (title, url, date, excerpt).
* Prompts (user):

  * Scope and desired tone/length.
* Output schema (example):

  ```json
  {
    "insights": [{
      "title": "string",
      "summary": "string",
      "implicationsForTCS": ["string"],
      "confidence": 0.0,
      "citations": ["evidenceId"]
    }],
    "narrative": {"thesis":"string","pillars":["string"],"risks":["string"]},
    "investments":[{"type":"string","name":"string","amount":"string?","date":"string?","citations":["evidenceId"]}],
    "platforms":[{"productName":"string","category":"string","capabilities":["string"],"citations":["evidenceId"]}]
  }
  ```

# UI Details & Components

* **Header**: App name ?Competitor AI Radar?, quick actions (Run Research, Export, Settings).
* **Tabs**: Scope, Research, Evidence, Insights, Compare, Catalog, Sources.
* **Cards**: KPI cards (Coverage %, #Sources, #Insights, Last Updated).
* **Tables**: sticky header, row selection, column filters.
* **Accordions**: show/hide long evidence.
* **Progress**: linear progress during fetch/summarize with ETA text.
* **Empty states**: clear guidance and CTA.
* **Visual polish**: use TCS Blue #0079C1 for primary, grey scale for neutrals, lots of whitespace, 8px grid, 2xl rounded corners, soft shadows.

# Example API Contracts

**`POST /api/research/start`**

```ts
type Body = {
  competitors: string[];
  topics: string[];
  timeWindow?: { from: string; to: string };
  regions?: string[];
  includeDomains?: string[];
  excludeDomains?: string[];
  depth?: "basic"|"advanced";
  maxResults?: number; // per competitor
};
type Response = { runId: string; queued: number };
```

**`GET /api/research/stream?runId=...`**

* SSE stream messages:

```ts
type Event =
 | { type: "status"; status: "queued"|"fetching"|"parsing"|"clustering"|"summarizing"|"done" }
 | { type: "progress"; fetched: number; deduped: number; coverage: number }
 | { type: "evidence"; item: Evidence }
 | { type: "error"; message: string };
```

**`POST /api/research/fetch`** (server action calls Tavily)

```ts
type Body = { competitor: string; topics: string[]; depth: "basic"|"advanced"; maxResults?: number; includeDomains?: string[]; excludeDomains?: string[]; };
```

**`POST /api/summarize/insights`** (server action calls OpenAI gpt-5)

```ts
type Body = { runId: string; tone: "board"|"tech"|"sales"; length: "1pager"|"brief"|"detailed"; };
```

# LLM Prompting Patterns

* **RAG grounding**: send only selected Evidence with strict instruction: ?Every sentence must be attributable to at least one citation id.?
* **Calibration**: ask model to rate confidence 0?1 and list ?What would increase confidence??
* **Comparisons**: chain-of-thought hidden; we only display the final JSON with score rationales (never reveal internal cot).

# Scoring & Heuristics

* Narrative clarity (0?5): coherence of AI story, customer focus, proof points.
* Investment intensity (0?5): frequency, size, recency of investments.
* Platform maturity (0?5): GA status, customer logos, SLAs, roadmap execution.
* Ecosystem (0?5): partnerships, integrations, dev docs, community signals.
* Velocity: derivative of change in above over last N months.

# Acceptance Criteria

* Users can:

  1. Enter competitors/topics and start a run.
  2. See progress live and browse evidence with filters.
  3. Generate an executive brief with citations and export it.
  4. Compare at least two competitors on a visual matrix with tooltips.
  5. View a catalog of AI narratives, investments, and platforms with source links.
* Every insight shows at least one citation with a clickable source.
* Exports render cleanly (PDF/PPTX) using the same color system and spacing.
* No secret keys leak to the client; all API calls are server-side.

# Demo Data & Research Seed (for local demo)

* Seed competitors: Accenture, Infosys, Wipro, Capgemini, Cognizant, IBM Consulting, HCLTech.
* Seed topics: ?GenAI strategy?, ?enterprise LLM platforms?, ?agents?, ?AI partnerships?, ?acquisitions?, ?industry solutions?.
* Provide a toggle ?Use demo data? that hydrates the Evidence Locker with a canned set of sources for offline demos.

# Visual & Brand

* Colors: Primary #0079C1 (TCS Blue), grayscale (Tailwind slate), white backgrounds.
* Typography: system UI stack; bold for headings; 14?16px base body; 24?28px section titles.
* Components: rounded-2xl cards, subtle shadows, ample padding, sticky action bars.
* Icons: lucide-react (book, search, briefcase, line-chart, file-text, bell).

# Implementation Notes

* Use React Server Components for data-heavy views; client components only for interactive tables and editors.
* Add simple rate limiting per IP in route handlers.
* Cache Tavily results by URL hash; refresh if older than 7 days.
* Normalize dates to ISO and show local time with ?N hours/days ago?.
* Log run metadata for reproducibility.

# Stretch (optional if time permits)

* ?What changed since last brief?? diff view.
* Slack/Teams share link with unfurl summary.
* Entity linking (companies, products, people) and per-entity timelines.
* Confidence calibration chart across insights.

---

**Build this exactly as specified above in a single pass. Keep the UI simple, quick to scan, and citation-first. Default to desktop (1440?900), responsive above 1280. Use TCS Blue #0079C1, greys, and white.**
